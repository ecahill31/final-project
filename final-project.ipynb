{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction of PubMed Publication Title Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pubmed: https://www.ncbi.nlm.nih.gov/pubmed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Search successful.\n"
    }
   ],
   "source": [
    "#importing needed packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from Bio import Entrez\n",
    "\n",
    "#searching PubMed for \"genomics\" and downloading dictionary of data including number of publications, accession IDs, and relevant MeSH term \n",
    "Entrez.email = \"eileen.cahill@nih.gov\"\n",
    "handle = Entrez.esearch(db=\"pubmed\", retmax=100, term=\"genom*\", idtype=\"acc\")\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "#optional print because data size is large\n",
    "#print(record)\n",
    "\n",
    "if record['Count'] == '0':\n",
    "    print(\"\\nYour search did not return any publications. Try another search.\\n\")\n",
    "    print(\"Error list says: \" + str(record['ErrorList']) + \"\\n\")\n",
    "    print(\"Warning list says: \" + str(record['WarningList']))\n",
    "else:\n",
    "    print(\"Search successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'Bio.Entrez.Parser.DictionaryElement'>\n"
    }
   ],
   "source": [
    "#simply showing data type\n",
    "print(type(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'>\n"
    }
   ],
   "source": [
    "#converting all data from type Bio.Entrez.Parser.DictionaryElement to list\n",
    "list = []\n",
    "listrecords = []\n",
    "\n",
    "for key, value in record.items():\n",
    "    list = [key, value]\n",
    "    listrecords.append(list)\n",
    "\n",
    "#optional: examine list of records (large)\n",
    "#print(listrecords)\n",
    "\n",
    "print(type(listrecords))\n",
    "#print(listrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#creating iterable list of IDs\n",
    "id_list_acquire = listrecords[3]\n",
    "#print(id_list_acquire)\n",
    "id_list = []\n",
    "id_list_int = []\n",
    "\n",
    "for id in id_list_acquire[1]:\n",
    "    id_list.append(id)\n",
    "#print(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search PubMed for title information using the PMIDs that resulted from the keyword search\n",
    "list_titles = []\n",
    "list_pmids = []\n",
    "\n",
    "for item in id_list:\n",
    "    handle2 = Entrez.esummary(db=\"pubmed\", id=item, retmode=\"xml\")\n",
    "    records2 = Entrez.parse(handle2)\n",
    "\n",
    "    for record in records2:\n",
    "        #each record is a Python dictionary or list.\n",
    "        list_titles.append(record['Title'])\n",
    "\n",
    "handle2.close()\n",
    "\n",
    "#print(list_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n0   [Transkranielle Gamma-Wechselstromstimulation ...\n1   Patients with high-risk DLBCL benefit from dos...\n2   De novo transcriptome sequence of Senna tora p...\n3   Evaluating the impact of trauma and PTSD on ep...\n4   Isolation of SARS-CoV-2-related coronavirus fr...\n..                                                ...\n95  VL30 retrotransposition is associated with ind...\n96  Effect of VX‑765 on the transcriptome profile ...\n97  Comprehensive analysis of aberrantly expressed...\n98  Comprehensive analysis of long non‑coding RNA ...\n99  A novel heterozygous mutation in the HMBS gene...\n\n[100 rows x 1 columns]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 1)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#showing the dataframe and shape\n",
    "df = pd.DataFrame(list_titles)\n",
    "print(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No empty fields detected.\n"
    }
   ],
   "source": [
    "#create one mass of text, replace special characters, and create all lowercase text\n",
    "text_glob = \"\"\n",
    "\n",
    "for x in list_titles:\n",
    "    text_glob += x\n",
    "\n",
    "if \"NaN\" in text_glob == True:\n",
    "    print(\"An empty field was found\")\n",
    "else:\n",
    "    print(\"No empty fields detected.\")\n",
    "\n",
    "text_glob = text_glob.replace(\".\", \" \")\n",
    "text_glob = text_glob.replace(\",\", \" \")\n",
    "text_glob = text_glob.replace(\":\", \" \")\n",
    "text_glob = text_glob.replace(\";\", \" \")\n",
    "text_glob = text_glob.replace(\"(\", \" \")\n",
    "text_glob = text_glob.replace(\")\", \" \")\n",
    "text_glob = text_glob.replace(\"?\", \" \")\n",
    "text_glob = text_glob.replace(\"&\", \" \")\n",
    "text_glob = text_glob.replace(\"'\", \" \")\n",
    "text_glob = text_glob.replace(\"<\", \" \")\n",
    "text_glob = text_glob.replace(\">\", \" \")\n",
    "text_glob = text_glob.replace(\"/i\", \" \")\n",
    "text_glob = text_glob.replace(\"[\", \" \")\n",
    "text_glob = text_glob.replace(\"]\", \" \")\n",
    "\n",
    "text_lower = text_glob.lower()\n",
    "\n",
    "#print(text_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('genomic', 11), ('cancer', 11), ('rna', 8), ('cell', 8), ('analysis', 7), ('gene', 6), ('human', 6), ('protein', 6), ('long', 5), ('delivery', 5), ('variant', 5), ('genetic', 5), ('genome', 5), ('using', 5), ('novel', 5)]\n<class 'list'>\n"
    }
   ],
   "source": [
    "#Tokenization and lemmatization steps <-- Text Preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Create word tokens and count frequencies\n",
    "tokens = word_tokenize(text_lower)\n",
    "#print(tokens)\n",
    "\n",
    "#removing stopwords and showing most frequent non-stopword words\n",
    "stops = set(stopwords.words('english'))\n",
    "stopwords = [x for x in tokens if x not in stops]\n",
    "#print(stopwords)\n",
    "\n",
    "#lemmatize words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    " \n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(word) for word in stopwords])\n",
    "#print(lemmatized_output)\n",
    "\n",
    "new_text_glob = word_tokenize(lemmatized_output)\n",
    "#print(new_text_glob)\n",
    "\n",
    "#printing most frequently used words\n",
    "freq_words = FreqDist(new_text_glob)\n",
    "most_freq_words = freq_words.most_common(15)\n",
    "print(most_freq_words)\n",
    "print(type(most_freq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['analysis', 'cancer', 'cell', 'delivery', 'gene', 'genetic', 'genome', 'genomic', 'human', 'long', 'novel', 'protein', 'rna', 'using', 'variant']\n    analysis  cancer  cell  delivery  gene  genetic  genome  genomic  human  \\\n0          0       0     0         0     0        0       0        1      0   \n1          0       1     0         0     0        0       0        0      0   \n2          0       0     0         0     0        0       0        0      0   \n3          0       0     1         0     0        0       0        0      0   \n4          1       0     0         0     0        0       0        0      0   \n5          0       0     0         0     1        0       0        0      0   \n6          0       0     0         0     0        0       0        0      1   \n7          0       0     0         0     0        0       0        0      0   \n8          0       0     0         0     0        0       0        0      0   \n9          0       0     0         1     0        0       0        0      0   \n10         0       0     0         0     0        0       0        0      0   \n11         0       0     0         0     0        1       0        0      0   \n12         0       0     0         0     0        0       1        0      0   \n13         0       0     0         0     0        0       0        0      0   \n14         0       0     0         0     0        0       0        0      0   \n\n    long  novel  protein  rna  using  variant  \n0      0      0        0    0      0        0  \n1      0      0        0    0      0        0  \n2      0      0        0    1      0        0  \n3      0      0        0    0      0        0  \n4      0      0        0    0      0        0  \n5      0      0        0    0      0        0  \n6      0      0        0    0      0        0  \n7      0      0        1    0      0        0  \n8      1      0        0    0      0        0  \n9      0      0        0    0      0        0  \n10     0      0        0    0      0        1  \n11     0      0        0    0      0        0  \n12     0      0        0    0      0        0  \n13     0      0        0    0      1        0  \n14     0      1        0    0      0        0  \n"
    }
   ],
   "source": [
    "#model the features using bag-of-words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "freq = []\n",
    "\n",
    "for x, y in most_freq_words:\n",
    "    freq.append(x)\n",
    "\n",
    "vectorizer1 = CountVectorizer()\n",
    "vectors = vectorizer1.fit_transform(freq)\n",
    "\n",
    "print(vectorizer1.get_feature_names())\n",
    "#print(vectors.toarray())\n",
    "\n",
    "freq = pd.DataFrame(data = vectors.toarray(), columns = vectorizer1.get_feature_names())\n",
    "\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Search successful.\n"
    }
   ],
   "source": [
    "#user performs a search which downloads a dictionary of data including number of publications, accession IDs, and relevant MeSH term \n",
    "Entrez.email = \"eileen.cahill@nih.gov\"\n",
    "handle2 = Entrez.esearch(db=\"pubmed\", retmax=100, term=\"genomic data\", idtype=\"acc\")\n",
    "record2 = Entrez.read(handle2)\n",
    "handle2.close()\n",
    "\n",
    "if record2['Count'] == '0':\n",
    "    print(\"\\nYour search did not return any publications. Try another search.\\n\")\n",
    "    print(\"Error list says: \" + str(record['ErrorList']) + \"\\n\")\n",
    "    print(\"Warning list says: \" + str(record['WarningList']))\n",
    "else:\n",
    "    print(\"Search successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['32380464', '32380242', '32380232', '32380203', '32380173', '32380006', '32379987', '32379866', '32379818', '32379805', '32379750', '32379494', '32379363', '32379360', '32379359', '32379347', '32379325', '32379315', '32379294', '32379020', '32378780', '32378719', '32378667', '32378381', '32377875', '32377739', '32377703', '32377572', '32377451', '32377449', '32377448', '32377365', '32377357', '32377353', '32377272', '32376980', '32376847', '32376789', '32376702', '32376654', '32376411', '32376136', '32376116', '32376044', '32375991', '32375986', '32375979', '32375946', '32375941', '32375935', '32375934', '32375933', '32375897', '32375827', '32375704', '32375690', '32375678', '32375645', '32375632', '32375599', '32375411', '32375395', '32375380', '32375339', '32375335', '32375210', '32375177', '32375154', '32375120', '32375029', '32374873', '32374870', '32374863', '32374823', '32374820', '32374793', '32374757', '32374727', '32374726', '32374631', '32374503', '32374423', '32374345', '32374294', '32374287', '32374252', '32374251', '32374079', '32374001', '32373753', '32373711', '32373647', '32373583', '32373535', '32373528', '32373524', '32373482', '32373288', '32373287', '32373220']\n"
    }
   ],
   "source": [
    "list2 = []\n",
    "listrecords2 = []\n",
    "\n",
    "for key, value in record2.items():\n",
    "    list2 = [key, value]\n",
    "    listrecords2.append(list2)\n",
    "\n",
    "#print(type(listrecords))\n",
    "#print(listrecords2)\n",
    "\n",
    "#creating iterable list of IDs\n",
    "id_list_acquire2 = listrecords2[3]\n",
    "#print(id_list_acquire)\n",
    "id_list2 = []\n",
    "\n",
    "for id in id_list_acquire2[1]:\n",
    "    id_list2.append(id)\n",
    "print(id_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n0   Durable Complete Response With Immune Checkpoi...\n1   Genomic analysis of one Multidrug-resistant Kl...\n2   miRDetect: A combinatorial approach for automa...\n3   Towards the quantum-enabled technologies for d...\n4   Recommendations for Clinical Warfarin Sensitiv...\n..                                                ...\n95  New Insights Into the Complex Mutational Lands...\n96  Optimization of Genotype by Sequencing data fo...\n97  Comparative effects of oncogenic mutations G12...\n98  MaREA4Galaxy: Metabolic reaction enrichment an...\n99  Integrative metagenomic and metabolomic analys...\n\n[100 rows x 1 columns]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(100, 1)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "#search PubMed for title information using the PMIDs that resulted from the keyword search\n",
    "list_titles2 = []\n",
    "list_pmids2 = []\n",
    "\n",
    "for item in id_list2:\n",
    "    handle4 = Entrez.esummary(db=\"pubmed\", id=item, retmode=\"xml\")\n",
    "    records4 = Entrez.parse(handle4)\n",
    "\n",
    "    for record in records4:\n",
    "        #each record is a Python dictionary or list.\n",
    "        list_titles2.append(record['Title'])\n",
    "\n",
    "    handle4.close()\n",
    "\n",
    "df2 = pd.DataFrame(list_titles2)\n",
    "print(df2)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No empty fields detected.\n"
    }
   ],
   "source": [
    "#create one mass of text, replace special characters, and create all lowercase text\n",
    "text_glob = \"\"\n",
    "\n",
    "for x in list_titles2:\n",
    "    text_glob += x\n",
    "\n",
    "if \"NaN\" in text_glob == True:\n",
    "    print(\"An empty field was found\")\n",
    "else:\n",
    "    print(\"No empty fields detected.\")\n",
    "\n",
    "text_glob = text_glob.replace(\".\", \" \")\n",
    "text_glob = text_glob.replace(\",\", \" \")\n",
    "text_glob = text_glob.replace(\":\", \" \")\n",
    "text_glob = text_glob.replace(\";\", \" \")\n",
    "text_glob = text_glob.replace(\"(\", \" \")\n",
    "text_glob = text_glob.replace(\")\", \" \")\n",
    "text_glob = text_glob.replace(\"?\", \" \")\n",
    "text_glob = text_glob.replace(\"&\", \" \")\n",
    "text_glob = text_glob.replace(\"'\", \" \")\n",
    "text_glob = text_glob.replace(\"<\", \" \")\n",
    "text_glob = text_glob.replace(\">\", \" \")\n",
    "text_glob = text_glob.replace(\"/i\", \" \")\n",
    "\n",
    "text_lower2 = text_glob.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('analysis', 16), ('cancer', 14), ('risk', 11), ('cell', 10), ('nov', 10), ('data', 9), ('disease', 9), ('patient', 9), ('study', 8), ('gene', 8), ('genomic', 7), ('novel', 7), ('sequencing', 7), ('model', 7), ('sp', 7)]\n<class 'list'>\n"
    }
   ],
   "source": [
    "#Tokenization and lemmatization steps <-- Text Preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Create word tokens and count frequencies\n",
    "tokens = word_tokenize(text_lower2)\n",
    "#print(tokens)\n",
    "\n",
    "#removing stopwords and showing most frequent non-stopword words\n",
    "stops = set(stopwords.words('english'))\n",
    "stopwords = [x for x in tokens if x not in stops]\n",
    "#print(stopwords)\n",
    "\n",
    "#lemmatize words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    " \n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(word) for word in stopwords])\n",
    "#print(lemmatized_output)\n",
    "\n",
    "new_text_glob = word_tokenize(lemmatized_output)\n",
    "#print(new_text_glob)\n",
    "\n",
    "#printing most frequently used words\n",
    "freq_words = FreqDist(new_text_glob)\n",
    "most_freq_words2 = freq_words.most_common(15)\n",
    "print(most_freq_words2)\n",
    "print(type(most_freq_words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['analysis', 'cancer', 'cell', 'data', 'disease', 'gene', 'genomic', 'model', 'nov', 'novel', 'patient', 'risk', 'sequencing', 'sp', 'study']\n    analysis  cancer  cell  data  disease  gene  genomic  model  nov  novel  \\\n0          1       0     0     0        0     0        0      0    0      0   \n1          0       1     0     0        0     0        0      0    0      0   \n2          0       0     0     0        0     0        0      0    0      0   \n3          0       0     1     0        0     0        0      0    0      0   \n4          0       0     0     0        0     0        0      0    1      0   \n5          0       0     0     1        0     0        0      0    0      0   \n6          0       0     0     0        1     0        0      0    0      0   \n7          0       0     0     0        0     0        0      0    0      0   \n8          0       0     0     0        0     0        0      0    0      0   \n9          0       0     0     0        0     1        0      0    0      0   \n10         0       0     0     0        0     0        1      0    0      0   \n11         0       0     0     0        0     0        0      0    0      1   \n12         0       0     0     0        0     0        0      0    0      0   \n13         0       0     0     0        0     0        0      1    0      0   \n14         0       0     0     0        0     0        0      0    0      0   \n\n    patient  risk  sequencing  sp  study  \n0         0     0           0   0      0  \n1         0     0           0   0      0  \n2         0     1           0   0      0  \n3         0     0           0   0      0  \n4         0     0           0   0      0  \n5         0     0           0   0      0  \n6         0     0           0   0      0  \n7         1     0           0   0      0  \n8         0     0           0   0      1  \n9         0     0           0   0      0  \n10        0     0           0   0      0  \n11        0     0           0   0      0  \n12        0     0           1   0      0  \n13        0     0           0   0      0  \n14        0     0           0   1      0  \n"
    }
   ],
   "source": [
    "#training a model, bag-of-words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "freq2 = []\n",
    "\n",
    "for x, y in most_freq_words2:\n",
    "    freq2.append(x)\n",
    "\n",
    "vectorizer2 = CountVectorizer()\n",
    "vectors = vectorizer2.fit_transform(freq2)\n",
    "\n",
    "print(vectorizer2.get_feature_names())\n",
    "#print(vectors.toarray())\n",
    "\n",
    "freq2 = pd.DataFrame(data = vectors.toarray(), columns = vectorizer2.get_feature_names())\n",
    "\n",
    "print(freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n['analysis', 'cancer', 'cell', 'delivery', 'gene', 'genetic', 'genome', 'genomic', 'human', 'long', 'novel', 'protein', 'rna', 'using', 'variant']\n['analysis', 'cancer', 'cell', 'data', 'disease', 'gene', 'genomic', 'model', 'nov', 'novel', 'patient', 'risk', 'sequencing', 'sp', 'study']\n"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(cosine_similarity(freq, freq2))\n",
    "print(vectorizer1.get_feature_names())\n",
    "print(vectorizer2.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/eileencahill/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     /Users/eileencahill/nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to\n[nltk_data]     /Users/eileencahill/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n[('NN', 579), ('JJ', 296), ('NNS', 37), ('VBG', 31), ('VBD', 26), ('VBP', 20), ('RB', 16), ('VBN', 16), ('CD', 11), ('IN', 11), ('VBZ', 6), ('FW', 5), ('JJS', 3), ('VB', 3), ('NNP', 2), ('JJR', 1), ('RBS', 1), ('RBR', 1)]\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "#Named Entity Recognition\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "tags = pos_tag(new_text_glob)\n",
    "chunk = ne_chunk(tags)\n",
    "\n",
    "#print(chunk)\n",
    "\n",
    "tags_freq = FreqDist(tag for (word, tag) in chunk)\n",
    "print(tags_freq.most_common())\n",
    "tags_freq.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  liraglutide/JJ\n  ameliorates/VBZ\n  lipotoxicity-induced/JJ\n  oxidative/JJ\n  stress/NN\n  activating/VBG\n  nrf2/JJ\n  (NP pathway/NN hepg2/NN)\n  cell/NN\n  mitochondrial/JJ\n  (NP dna/NN segregation/NN)\n  (NP replication/NN restrict/NN)\n  transmission/NN\n  detrimental/JJ\n  (NP mutation/NN onset/NN)\n  hippocampal/JJ\n  (NP network/NN aberration/NN)\n  (NP memory/NN deficit/NN)\n  (NP p301s/NN tau/NN)\n  mouse/NN\n  associated/VBN\n  early/JJ\n  (NP gene/NN signature/NN)\n  nasa/FW\n  (NP twin/NN study/NN)\n  effect/NN\n  one/CD\n  (NP year/NN space/NN)\n  long-chain/NN\n  fatty/JJ\n  acid/NN\n  desaturases/VBZ\n  elongases/VBZ\n  primary/JJ\n  hyperparathyroidism/NN\n  first/JJ\n  (NP manifestation/NN men/NNS)\n  2a/CD\n  international/JJ\n  (NP multicenter/NN study/NN)\n  suppression/NN\n  inflammasome/JJ\n  (NP activation/NN irf8/NN)\n  (NP irf4/NN cdc/NN)\n  critical/JJ\n  cell/NN\n  priming/VBG\n  (NP senataxin/NN ortholog/NN)\n  sen1/JJ\n  (NP limit/NN dna/NN)\n  rna/VBP\n  hybrid/JJ\n  (NP accumulation/NN dna/NN)\n  double-strand/JJ\n  (NP break/NN control/NN)\n  end/JJ\n  (NP resection/NN repair/NN)\n  (NP fidelity/NN variation/NN)\n  human/JJ\n  neural/JJ\n  (NP stem/NN cell/NN)\n  generating/VBG\n  organizer/JJ\n  (NP state/NN vitro/NN)\n  committing/VBG\n  cortical/JJ\n  excitatory/NN\n  inhibitory/JJ\n  neuronal/JJ\n  (NP fate/NN interstitial/NN)\n  cell/NN\n  remodeling/VBG\n  promotes/NNS\n  aberrant/JJ\n  adipogenesis/NN\n  dystrophic/JJ\n  muscle/NN\n  fine/JJ\n  chromatin-driven/JJ\n  (NP mechanism/NN transcription/NN)\n  (NP interference/NN antisense/NN)\n  noncoding/VBG\n  (NP transcription/NN loss/NN)\n  sup/NN\n  1/CD\n  (NP /sup/NN acp/NN)\n  sup/VBD\n  3/CD\n  (NP /sup/NNP ψ/NNP)\n  ribosomal/JJ\n  (NP rna/NN modification/NN)\n  major/JJ\n  (NP feature/NN cancer/NN)\n  genome-wide/JJ\n  survey/NN\n  ribosome/JJ\n  (NP collision/NN challenge/NN)\n  establishing/VBG\n  (NP pure/NN lung/NN)\n  (NP cancer/NN organoids/NNS)\n  limit/VBP\n  utility/NN\n  personalized/VBN\n  medicine/JJ\n  quantitative/JJ\n  framework/NN\n  evaluating/VBG\n  (NP single-cell/JJ data/NNS)\n  (NP structure/NN preservation/NN)\n  (NP dimensionality/NN reduction/NN)\n  technique/NN\n  representative/JJ\n  sequencing/NN\n  unbiased/JJ\n  sampling/NN\n  solid/JJ\n  (NP tumor/NN tissue/NN)\n  (NP gene/NN regulation/NN)\n  equilibrium/NN\n  müllerian/JJ\n  mimicry/NN\n  quantitative/JJ\n  trait/NN\n  despite/IN\n  contrasting/VBG\n  level/JJ\n  genomic/JJ\n  (NP divergence/NN selection/NN)\n  genetic/JJ\n  basis/NN\n  animal/JJ\n  behavioural/JJ\n  diversity/NN\n  natural/JJ\n  population/NN\n  mutational/JJ\n  dynamic/JJ\n  immune/JJ\n  evasion/NN\n  diffuse/IN\n  large/JJ\n  b-cell/JJ\n  lymphoma/NN\n  explored/VBD\n  relapse-enriched/JJ\n  patient/JJ\n  series/NN\n  human/JJ\n  telomeric/JJ\n  (NP nucleosome/NN display/NN)\n  distinct/JJ\n  structural/JJ\n  dynamic/JJ\n  (NP property/NN eif4g/NN)\n  intrinsic/JJ\n  g-quadruplex/JJ\n  (NP binding/NN activity/NN)\n  required/VBN\n  tirna/JJ\n  function/NN\n  ampliconic/JJ\n  gene/NN\n  great/JJ\n  ape/JJ\n  chromosome/NN\n  rapid/JJ\n  (NP evolution/NN copy/NN)\n  (NP number/NN conservation/NN)\n  (NP expression/NN level/NN)\n  development/NN\n  single-stranded/JJ\n  dna-binding/JJ\n  protein/NN\n  fluorescent/JJ\n  (NP fusion/NN toolbox/NN)\n  mieaa/VBD\n  2/CD\n  0/CD\n  integrating/VBG\n  multi-species/NNS\n  microrna/JJ\n  enrichment/JJ\n  analysis/NN\n  workflow/VB\n  (NP management/NN system/NN)\n  comparative/JJ\n  (NP metabolome/NN transcriptome/NN)\n  analysis/NN\n  susceptible/JJ\n  (NP asparagus/NN officinalis/NN)\n  resistant/JJ\n  wild/JJ\n  kiusianus/NN\n  revealed/VBD\n  insight/JJ\n  stem/NN\n  blight/VBD\n  disease/JJ\n  (NP resistance/NN crispr-cas12a/NN)\n  (NP system/NN fission/NN)\n  yeast/NN\n  multiplex/JJ\n  genomic/JJ\n  editing/VBG\n  crispr/JJ\n  interference/NN\n  quest/JJS\n  orthologs/NNS\n  (NP benchmark/NN service/NN)\n  (NP consensus/NN call/NN)\n  2020/CD\n  evolutionary/JJ\n  (NP selection/NN pestivirus/NN)\n  variant/NN\n  altered/VBD\n  microrna/JJ\n  (NP dependency/NN omics/NNS)\n  discovery/JJ\n  (NP rest/NN interface/NN)\n  (NP plant/NN animal/NN)\n  chromatin/NN\n  3d/CD\n  organization/NN\n  similar/JJ\n  structure/NN\n  different/JJ\n  (NP function/NN indirect/NN)\n  prediction/NN\n  large/JJ\n  number/NN\n  genotyped/VBD\n  animal/JJ\n  using/VBG\n  algorithm/JJ\n  proven/JJ\n  young1/JJR\n  covid-2019/NN\n  associated/VBN\n  overexpressed/JJ\n  (NP prevotella/NN protein/NN)\n  mediated/VBD\n  host-pathogen/JJ\n  (NP interaction/NN role/NN)\n  coronavirus/NN\n  outbreak/VBP\n  thyroid/JJ\n  (NP function/NN affect/NN)\n  risk/NN\n  stroke/VBD\n  via/IN\n  atrial/JJ\n  fibrillation/NN\n  mendelian/JJ\n  (NP randomization/NN study/NN)\n  scientific/JJ\n  workflow/NN\n  (NP manager/NN metabolomics/NNS)\n  overview/VBP\n  proximity/NN\n  (NP biotinylation/NN reveals/NNS)\n  (NP novel/RB)\n  secreted/VBD\n  dense/JJ\n  (NP granule/NN protein/NN)\n  (NP toxoplasma/NN gondii/NN)\n  bradyzoites/VBZ\n  (NP presence/NN hpv/NN)\n  (NP overexpression/NN p16ink4a/NN)\n  protein/NN\n  ebv/JJ\n  infection/NN\n  penile/IN\n  cancer-a/JJ\n  (NP series/NN case/NN)\n  brazil/JJ\n  amazon/NN\n  comprehensive/JJ\n  analysis/NN\n  (NP translationally/RB)\n  controlled/VBD\n  (NP tumor/NN protein/NN)\n  tctp/NN\n  provides/VBZ\n  insight/JJ\n  lineage-specific/JJ\n  evolution/NN\n  functional/JJ\n  divergence/NN\n  genomic/JJ\n  landscape/NN\n  metastatic/JJ\n  (NP breast/NN cancer/NN)\n  insight/VBD\n  11/CD\n  000/CD\n  tumor/NN\n  transcriptome/JJ\n  parasitic/JJ\n  (NP flatworm/NN schistosoma/NN)\n  mansoni/RBS\n  intra-mammalian/JJ\n  (NP development/NN phylogeny/NN)\n  (NP taxonomy/NN powdery/NN)\n  (NP mildew/NN viburnum/NN)\n  specie/NN\n  personalized/VBN\n  network/NN\n  modeling/VBG\n  pan-cancer/JJ\n  (NP patient/NN cell/NN)\n  line/NN\n  interactome/JJ\n  molecular/JJ\n  (NP epidemiology/NN phylodynamics/NNS)\n  goose/VBP\n  hemorrhagic/JJ\n  polyomavirus/NN\n  balancing/VBG\n  (NP selection/NN pattern/NN)\n  (NP recognition/NN receptor/NN)\n  (NP signalling/VBG pathway/RB)\n  associated/VBN\n  (NP gene/NN function/NN)\n  pleiotropy/FW\n  wild/JJ\n  (NP rodent/NN construct/NN)\n  (NP validity/NN sensitivity/NN)\n  specificity/NN\n  uscd/JJ\n  performance-based/JJ\n  skill/NN\n  assessment/VBD\n  2/CD\n  mixed/JJ\n  portuguese/JJ\n  sample/JJ\n  sars-cov-2/JJ\n  (NP spike/NN glycoprotein/NN)\n  structural/JJ\n  diversity/NN\n  phylogeny/VBP\n  potential/JJ\n  (NP animal/NN host/NN)\n  identification/NN\n  (NP treatment/NN regimen/NNS)\n  administration/NN\n  anti-vascular/JJ\n  endothelial/JJ\n  (NP growth/NN factor/NN)\n  agent/NN\n  neovascular/JJ\n  age-related/JJ\n  macular/JJ\n  (NP degeneration/NN metabolic/NN)\n  (NP engineering/NN strategy/NN)\n  (NP butanol/NN production/NN)\n  escherichia/FW\n  coli/JJ\n  (NP identification/NN susceptibility/NN)\n  locus/VBP\n  spontaneous/JJ\n  coronary/JJ\n  (NP artery/NN dissection/NN)\n  (NP bivariate/NN trait/NN)\n  (NP association/NN analysis/NN)\n  using/VBG\n  generalized/VBN\n  estimating/VBG\n  equation/NN\n  (NP family/NN data/NNS)\n  comparison/NN\n  optimization-modelling/JJ\n  (NP method/NN metabolite/NN)\n  production/NN\n  escherichia/FW\n  (NP coli/NN histone/NN)\n  (NP modification/NN reader/NN)\n  zcwpw1/NN\n  link/VBP\n  histone/CD\n  methylation/NN\n  prdm9-induced/JJ\n  double/JJ\n  (NP strand/NN break/NN)\n  (NP repair/NN modestobacter/NN)\n  (NP altitudinis/NN sp/NN)\n  nov/NN\n  novel/JJ\n  actinobacterium/NN\n  isolated/VBD\n  atacama/JJ\n  desert/JJ\n  soil/NN\n  genomic/JJ\n  (NP profiling/NN escherichia/NN)\n  coli/NN\n  isolates/VBZ\n  bacteraemia/JJ\n  patient/JJ\n  3-year/JJ\n  cohort/NN\n  (NP study/NN isolates/NNS)\n  collected/VBD\n  sydney/NN\n  teaching/VBG\n  (NP hospital/NN comparison/NN)\n  (NP virulence/NN gene/NN)\n  antimicrobial/JJ\n  (NP resistance/NN profile/NN)\n  genetic/JJ\n  diversity/NN\n  avian/JJ\n  pathogenic/JJ\n  (NP escherichia/NN coli/NN)\n  apec/NN\n  isolates/VBZ\n  broiler/IN\n  (NP broiler/NN breeder/NN)\n  thailand/NN\n  (NP australia/RB)\n  biological/JJ\n  characteristic/JJ\n  whole-genome/JJ\n  (NP analysis/NN enterococcus/NN)\n  faecalis/JJ\n  (NP phage/NN pef771/NN)\n  lncrnas/VBZ\n  classifier/RBR\n  (NP accurately/RB)\n  predict/JJ\n  recurrence/NN\n  thymic/JJ\n  epithelial/JJ\n  tumor/NN\n  clinical/JJ\n  (NP display/NN diagnostics/NNS)\n  genetic/JJ\n  (NP implication/NN novel/NN)\n  coronavirus/NN\n  covid-19/JJ\n  epidemic/JJ\n  viral/JJ\n  epidemiologic/JJ\n  clinical/JJ\n  characteristic/JJ\n  (NP potential/NN therapy/NN)\n  option/NN\n  covid-19/JJ\n  (NP review/NN association/NN)\n  c-myc/JJ\n  k-ras/JJ\n  (NP gene/NN polymorphism/NN)\n  non-hodgkin/JJ\n  (NP lymphoma/NN cleft/NN)\n  lip/palate/VBP\n  educational/JJ\n  (NP attainment/NN cause/NN)\n  (NP consequence/NN correlation/NN)\n  mendelian-randomization/NN\n  (NP study/NN within-species/NNS)\n  variation/NN\n  omv/IN\n  (NP cargo/NN protein/NN)\n  (NP myxococcus/NN xanthus/NNP)\n  omv/VBZ\n  pan-proteome/JJ\n  achieving/VBG\n  congruence/NN\n  among/IN\n  (NP reference/NN laboratory/NN)\n  absolute/JJ\n  (NP abundance/NN measurement/NN)\n  analytes/VBZ\n  rare/JJ\n  (NP disease/NN psychosine/NN)\n  (NP diagnosis/NN prognosis/NN)\n  (NP krabbe/NN disease/NN)\n  comparative/JJ\n  performance/NN\n  pooled/VBD\n  cohort/JJ\n  (NP equation/NN framingham/NN)\n  risk/NN\n  score/VBP\n  cardiovascular/JJ\n  (NP disease/NN risk/NN)\n  (NP classification/NN slum/NN)\n  setting/VBG\n  (NP nairobi/JJ kenya/NNS)\n  (NP importance/NN tissue/NN)\n  selection/NN\n  genetic/JJ\n  testing/VBG\n  detection/NN\n  terminal/JJ\n  18q/CD\n  (NP deletion/NN stem/NN)\n  (NP cell/NN transplantation/NN)\n  ipsc-derived/JJ\n  (NP intestinal/JJ organoids/NNS)\n  cystic/JJ\n  (NP fibrosis/NN patient/NN)\n  acquire/VB\n  (NP cftr/NN activity/NN)\n  upon/IN\n  talen-mediated/JJ\n  repair/NN\n  p/JJ\n  (NP f508del/NN mutation/NN)\n  high/JJ\n  (NP carriage/NN rate/NN)\n  multidrug-resistant/JJ\n  (NP gram-negative/JJ bacteria/NNS)\n  neonatal/JJ\n  intensive/JJ\n  (NP care/NN unit/NN)\n  (NP ghana/NN development/NN)\n  digital/JJ\n  rt-pcr/JJ\n  (NP method/NN absolute/NN)\n  (NP quantification/NN bluetongue/NN)\n  (NP virus/NN field/NN)\n  sample/JJ\n  developing/VBG\n  multi-layer/JJ\n  (NP deep/NN learning/NN)\n  based/VBN\n  predictive/JJ\n  model/NN\n  identify/VB\n  dna/JJ\n  n4-methylcytosine/JJ\n  (NP modification/NN overexpression/NN)\n  global/JJ\n  regulator/NN\n  pbrlaea/JJ\n  (NP lead/NN discovery/NN)\n  new/JJ\n  polyketide/NN\n  fungus/JJ\n  (NP penicillium/NN brocae/NN)\n  hdn-12-143/JJ\n  clinical/JJ\n  genetic/JJ\n  heterogeneity/NN\n  six/CD\n  tunisian/JJ\n  (NP family/NN horizontal/NN)\n  (NP gaze/NN palsy/NN)\n  progressive/JJ\n  (NP scoliosis/NN retrospective/NN)\n  study/NN\n  13/CD\n  (NP case/NN investigation/NN)\n  effect/NN\n  transfected/VBD\n  defective/JJ\n  (NP ebola/NN virus/NN)\n  (NP genome/NN ebola/NN)\n  replication/NN\n  functional/JJ\n  identification/NN\n  structural/JJ\n  analysis/NN\n  new/JJ\n  (NP lipoate/NN protein/NN)\n  ligase/NN\n  mycoplasma/JJ\n  hyopneumoniae/JJ\n  gcn2-like/JJ\n  kinase/NN\n  modulates/VBZ\n  stress/JJ\n  (NP granule/NN formation/NN)\n  nutritional/JJ\n  (NP stress/NN trypanosoma/NN)\n  (NP cruzi/NN novel/NN)\n  scoring/VBG\n  (NP system/NN risk/NN)\n  assessment/VBP\n  elderly/JJ\n  patient/NN\n  (NP cytogenetically/RB)\n  normal/JJ\n  acute/JJ\n  (NP myeloid/NN leukemia/NN)\n  based/VBN\n  expression/NN\n  three/CD\n  (NP aqp1/NN dna/NN)\n  methylation-associated/JJ\n  gene/NN\n  comprehensive/JJ\n  genomic/JJ\n  profiling/NN\n  rare/JJ\n  (NP tumor/NN route/NN)\n  targeted/VBD\n  therapy/JJ\n  new/JJ\n  insight/NN\n  complex/JJ\n  mutational/JJ\n  landscape/NN\n  sézary/JJ\n  syndrome/JJ\n  clinical/JJ\n  biological/JJ\n  significance/NN\n  methyltransferase-related/JJ\n  (NP signature/NN diffuse/NN)\n  (NP glioma/NN sirt4/NN)\n  multifaceted/VBD\n  enzyme/JJ\n  crossroad/NN\n  mitochondrial/JJ\n  (NP metabolism/NN cancer/NN)\n  (NP optimization/NN genotype/NN)\n  sequencing/VBG\n  data/NNS\n  phylogenetic/JJ\n  purpose/JJ\n  zebrafish/JJ\n  integrative/JJ\n  (NP vertebrate/NN model/NN)\n  identify/VB\n  mirna/JJ\n  mechanism/NN\n  regulating/VBG\n  toxicity/NN\n  epigenetic/JJ\n  mechanism/NN\n  neurodevelopmental/JJ\n  (NP theory/NN depression/NN)\n  effect/NN\n  nano-copper/JJ\n  (NP maize/NN yield/NN)\n  inflammatory/JJ\n  (NP response/NN mouse/NN)\n  comparative/JJ\n  effect/NN\n  oncogenic/JJ\n  (NP mutation/NN g12c/NN)\n  (NP g12v/NN g13d/NN)\n  q61h/JJ\n  local/JJ\n  conformation/NN\n  dynamic/JJ\n  k-ras/JJ\n  marea4galaxy/NN\n  metabolic/JJ\n  (NP reaction/NN enrichment/NN)\n  (NP analysis/NN visualization/NN)\n  (NP rna-seq/NN data/NNS)\n  within/IN\n  galaxy/JJ\n  mir-182-3p/myadm/JJ\n  contribute/NN\n  pulmonary/JJ\n  (NP artery/NN hypertension/NN)\n  vascular/JJ\n  remodeling/VBG\n  via/IN\n  klf4/p21-dependent/JJ\n  (NP mechanism/NN review/NN)\n  emerging/VBG\n  physical/JJ\n  (NP transfection/NN method/NN)\n  crispr/cas9-mediated/JJ\n  gene/NN\n  editing/VBG\n  integrative/JJ\n  metagenomic/JJ\n  metabolomic/JJ\n  (NP analysis/NN reveal/NN)\n  severity-specific/JJ\n  (NP signature/NN gut/NN)\n  microbiota/NN\n  chronic/JJ\n  (NP kidney/NN disease/NN)\n  heritable/JJ\n  modifier/JJR\n  (NP tumor/NN microenvironment/NN)\n  (NP influence/NN nanoparticle/NN)\n  uptake/JJ\n  (NP distribution/NN response/NN)\n  photothermal/JJ\n  (NP therapy/NN editorial/NN)\n  precise/JJ\n  genome/NN\n  editing/VBG\n  technique/JJ\n  (NP application/NN development/NN)\n  early/JJ\n  (NP prediction/NN model/NN)\n  subarachnoid/JJ\n  hemorrhage/NN\n  genetic/JJ\n  signaling/VBG\n  (NP pathway/NN analysis/NN)\n  de/IN\n  novo/FW\n  (NP assembly/RB)\n  genome-wide/JJ\n  (NP snp/NN discovery/NN)\n  (NP rohu/NN carp/NN)\n  labeo/NN\n  rohita/JJ\n  role/NN\n  genetic/JJ\n  (NP variation/NN bmi/NN)\n  (NP body/NN composition/NN)\n  fat/JJ\n  distribution/NN\n  mental/JJ\n  (NP trait/NN disorder/NN)\n  look-up/JJ\n  mendelian/JJ\n  (NP randomization/NN study/NN)\n  calcium-sensing/JJ\n  (NP receptor/NN gene/NN)\n  polymorphism/NN\n  casrv1/VBP\n  casrv2/JJ\n  physical/JJ\n  activity/NN\n  (NP level/NN men/NNS)\n  lower/JJR\n  (NP silesia/NN poland/NN)\n  integrated/VBN\n  landscape/JJ\n  biological/JJ\n  (NP candidate/NN causal/NN)\n  gene/NN\n  coronary/JJ\n  (NP artery/NN disease/NN)\n  preliminary/JJ\n  study/NN\n  investigate/JJ\n  genetic/JJ\n  (NP background/NN longevity/NN)\n  based/VBN\n  whole-genome/JJ\n  (NP sequence/NN data/NNS)\n  two/CD\n  methuselah/JJ\n  dog/NN\n  genome-wide/JJ\n  analysis/NN\n  methylation-driven/JJ\n  (NP gene/NN identification/NN)\n  eight-gene/JJ\n  (NP panel/NN prognosis/NN)\n  (NP prediction/NN breast/NN)\n  cancer/NN\n  identifying/VBG\n  shared/VBN\n  (NP risk/NN gene/NN)\n  asthma/JJ\n  (NP hay/NN fever/NN)\n  eczema/VBZ\n  multi-trait/JJ\n  multiomic/JJ\n  (NP association/NN analysis/NN)\n  genomic/JJ\n  (NP breeding/NN program/NN)\n  realize/NN\n  larger/JJR\n  benefit/JJ\n  (NP cooperation/NN presence/NN)\n  (NP genotype/NN ×/NNP)\n  (NP environment/NN interaction/NN)\n  conventional/JJ\n  (NP breeding/NN program/NN)\n  drug/NN\n  targeting/VBG\n  genomic/JJ\n  instability/NN\n  multiple/JJ\n  myeloma/NN\n  whole/JJ\n  genome/JJ\n  (NP scan/JJ reveals/NNS)\n  molecular/JJ\n  (NP signature/NN divergence/NN)\n  selection/NN\n  related/VBN\n  important/JJ\n  (NP trait/NN durum/NN)\n  (NP wheat/NN germplasm/NN))\n"
    }
   ],
   "source": [
    "#Establishing rules for chunking\n",
    "from nltk.chunk import *\n",
    "from nltk.chunk.util import *\n",
    "from nltk.chunk.regexp import *\n",
    "\n",
    "rules = r'''\n",
    "NP: {<JJ><NN.>}\n",
    "    {<VB.>*<RB>}\n",
    "    {<NN><NN.>+}\n",
    "    {<VP><NN.>+}\n",
    "    {<NN.><RB>+}\n",
    "    {<NNP>+}\n",
    "    {<NN><NN>}\n",
    "    '''\n",
    "chunkparse = RegexpParser(rules)\n",
    "result = chunkparse.parse(tags)\n",
    "print(result)\n",
    "result.draw()\n",
    "#print(tags)\n",
    "#nouns = noun for noun in result if tags == \"NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will be helpful for NIH administrators to know which aspects of a certain scientific area are most common in publications and which are least common. For example if we know that \"human\" is the most common term in a PubMed search of \"genomics\" publications, then we can learn that there is a strong human emphasis in genomic research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondad7e997a9f21d4c48a1361726b45a74df"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}